# RF6 - Avalia√ß√£o em Tempo Real das Respostas (Live Assessments)

## üìã Vis√£o Geral

O RF6 implementa o sistema de **avalia√ß√£o autom√°tica e manual de respostas de entrevista** do TalentMatchIA. Permite que o sistema avalie automaticamente via IA as respostas dos candidatos e que recrutadores ajustem os scores manualmente, garantindo um processo de avalia√ß√£o h√≠brido (IA + humano) mais preciso.

### Principais Funcionalidades

- ‚úÖ **Avalia√ß√£o autom√°tica via IA** (OpenRouter/Grok) de respostas
- ‚úÖ **Ajuste manual** de scores e feedback pelo entrevistador
- ‚úÖ **Concord√¢ncia IA vs Humano** (m√©tricas de discrep√¢ncia)
- ‚úÖ **CRUD completo** de avalia√ß√µes
- ‚úÖ **M√©tricas e KPIs** (taxa de ajuste, scores m√©dios, concord√¢ncia)
- ‚úÖ **Categoriza√ß√£o** por tipo (behavioral, technical, situational, cultural, general)
- ‚úÖ **Tracking de tempo de resposta** para an√°lise de performance
- ‚úÖ **Soft delete** para preservar hist√≥rico de auditoria

---

## üóÑÔ∏è Banco de Dados

### Migration 018: Tabela `live_assessments`

```sql
CREATE TABLE live_assessments (
  id UUID PRIMARY KEY,
  company_id UUID NOT NULL,
  interview_id UUID NOT NULL,
  question_id UUID,                     -- Link para pergunta (opcional)
  answer_id UUID,                       -- Link para resposta (opcional)
  
  -- Scores
  score_auto NUMERIC(4,2),              -- Score IA (0-10)
  score_manual NUMERIC(4,2),            -- Score ajustado (0-10)
  score_final NUMERIC(4,2),             -- Calculado automaticamente
  
  -- Feedback
  feedback_auto JSONB,                  -- { nota, feedback, pontosFortesResposta, pontosMelhoria }
  feedback_manual TEXT,                 -- Coment√°rio do avaliador
  
  -- Metadados
  assessment_type TEXT CHECK (type IN ('behavioral', 'technical', 'situational', 'cultural', 'general')),
  status TEXT DEFAULT 'pending' CHECK (status IN ('pending', 'auto_evaluated', 'manually_adjusted', 'validated', 'invalidated')),
  response_time_seconds INTEGER,        -- Tempo de resposta do candidato
  
  -- Auditoria
  evaluated_by UUID,
  evaluated_at TIMESTAMP,
  created_by UUID,
  created_at TIMESTAMP DEFAULT now(),
  updated_at TIMESTAMP DEFAULT now(),
  deleted_at TIMESTAMP
);
```

**√çndices:** 8 √≠ndices (company, interview, question, status, type, created_at, scores, date)

**Triggers:** `trigger_update_live_assessments` - Auto-atualiza `updated_at`, `score_final` e `status`

---

### Migration 019: Views de M√©tricas

1. **`assessment_stats_overview`** - Estat√≠sticas gerais (total, m√©dias, recentes)
2. **`assessment_by_interview`** - Avalia√ß√µes por entrevista com scores min/max/avg
3. **`assessment_type_distribution`** - Distribui√ß√£o por tipo com taxa de ajuste manual
4. **`assessment_concordance_stats`** - Concord√¢ncia IA vs humano (diferen√ßas, taxas)
5. **`assessment_performance_timeline`** - Timeline di√°ria de avalia√ß√µes

**Fun√ß√£o:** `get_assessment_metrics(company_id)` retorna 8 m√©tricas consolidadas

---

## üöÄ API Endpoints

### Base URL: `/api/live-assessments`

---

### 1. **Criar Avalia√ß√£o**

```http
POST /api/live-assessments
```

**Request Body (Avalia√ß√£o Autom√°tica):**
```json
{
  "interview_id": "uuid",
  "question_id": "uuid",              // Ou question_text
  "answer_id": "uuid",                // Ou answer_text
  "assessment_type": "technical",
  "response_time_seconds": 180,
  "auto_evaluate": true               // Chama IA para avaliar
}
```

**Request Body (Manual - Sem IA):**
```json
{
  "interview_id": "uuid",
  "question_text": "Como voc√™ lida com feedback negativo?",
  "answer_text": "Eu sempre procuro ouvir atentamente...",
  "assessment_type": "behavioral",
  "auto_evaluate": false
}
```

**Response 201:**
```json
{
  "success": true,
  "message": "Avalia√ß√£o criada com sucesso",
  "data": {
    "id": "uuid",
    "score_auto": 8.5,
    "feedback_auto": {
      "nota": 8.5,
      "feedback": "Resposta t√©cnica bem fundamentada...",
      "pontosFortesResposta": ["conhecimento de arquitetura", "clareza"],
      "pontosMelhoria": ["detalhar estrat√©gias de fallback"]
    },
    "status": "auto_evaluated"
  }
}
```

---

### 2. **Listar Avalia√ß√µes**

```http
GET /api/live-assessments
```

**Query Parameters:**
- `interview_id` - Filtrar por entrevista
- `status` - pending | auto_evaluated | manually_adjusted | validated | invalidated
- `assessment_type` - behavioral | technical | situational | cultural | general
- `sort_by` - created_at | score_final | status
- `order` - ASC | DESC
- `page` - P√°gina (default: 1)
- `limit` - Itens por p√°gina (default: 20, max: 100)

**Response 200:**
```json
{
  "success": true,
  "data": [
    {
      "id": "uuid",
      "score_final": 8.5,
      "status": "auto_evaluated",
      "question_text": "Explique event-driven architecture",
      "answer_text": "Event-driven √©...",
      "feedback_auto": {...},
      "created_at": "2025-11-22T10:00:00Z"
    }
  ],
  "pagination": {
    "page": 1,
    "limit": 20,
    "total": 45,
    "totalPages": 3
  }
}
```

---

### 3. **Obter Detalhes**

```http
GET /api/live-assessments/:id
```

**Response 200:** Retorna avalia√ß√£o completa com pergunta, resposta, entrevista e nomes dos usu√°rios.

---

### 4. **Atualizar Avalia√ß√£o (Ajuste Manual)**

```http
PUT /api/live-assessments/:id
```

**Request Body:**
```json
{
  "score_manual": 9.0,
  "feedback_manual": "Excelente resposta t√©cnica. Demonstrou conhecimento profundo.",
  "status": "validated"
}
```

**Comportamento:**
- `score_manual` altera `status` para `manually_adjusted`
- `evaluated_by` e `evaluated_at` s√£o preenchidos automaticamente
- `score_final` √© recalculado (prioriza `score_manual` sobre `score_auto`)

---

### 5. **Invalidar Avalia√ß√£o**

```http
DELETE /api/live-assessments/:id
```

**Permiss√µes:** ADMIN, SUPER_ADMIN

**Comportamento:** Soft delete + `status = 'invalidated'`

---

### 6. **Avalia√ß√µes por Entrevista**

```http
GET /api/live-assessments/interview/:interview_id
```

**Response 200:**
```json
{
  "success": true,
  "data": [ /* array de avalia√ß√µes */ ],
  "stats": {
    "total_assessments": 10,
    "avg_score": "8.25",
    "auto_evaluated": 7,
    "manually_adjusted": 3
  }
}
```

---

### 7. **M√©tricas Consolidadas**

```http
GET /api/dashboard/assessments/metrics
```

**Response 200:**
```json
{
  "success": true,
  "data": {
    "metrics": {
      "total_assessments": { "value": 156, "label": "Total de avalia√ß√µes realizadas" },
      "auto_evaluated_count": { "value": 120, "label": "Avalia√ß√µes autom√°ticas (IA)" },
      "manually_adjusted_count": { "value": 36, "label": "Avalia√ß√µes ajustadas manualmente" },
      "manual_adjustment_rate": { "value": 23.08, "label": "% ajustadas manualmente" },
      "avg_score_final": { "value": 7.85, "label": "Score m√©dio final" },
      "concordance_rate": { "value": 78.50, "label": "% concord√¢ncia IA vs humano (diff <= 1)" },
      "avg_response_time": { "value": 142.30, "label": "Tempo m√©dio de resposta (segundos)" },
      "assessments_last_7_days": { "value": 23, "label": "Avalia√ß√µes nos √∫ltimos 7 dias" }
    },
    "by_type": [
      { "assessment_type": "technical", "total_count": 65, "avg_score": 8.10, "manual_adjustment_rate": 20.00 },
      { "assessment_type": "behavioral", "total_count": 45, "avg_score": 7.80, "manual_adjustment_rate": 25.00 }
    ],
    "concordance": {
      "dual_scored_count": 36,
      "avg_score_difference": 0.85,
      "concordance_rate": 78.50,
      "discordance_rate": 12.50
    }
  }
}
```

---

### 8. **Timeline de Avalia√ß√µes**

```http
GET /api/dashboard/assessments/timeline?days=30
```

**Response 200:** Retorna array com estat√≠sticas di√°rias dos √∫ltimos N dias.

---

### 9. **Avalia√ß√µes por Entrevista (Dashboard)**

```http
GET /api/dashboard/assessments/by-interview
```

**Response 200:** Retorna √∫ltimas 50 entrevistas com estat√≠sticas de avalia√ß√£o.

---

## üîê Seguran√ßa e Permiss√µes

| Endpoint | SUPER_ADMIN | ADMIN | RECRUITER | CANDIDATE |
|----------|-------------|-------|-----------|-----------|
| POST /live-assessments | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùå |
| GET /live-assessments | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùå |
| GET /live-assessments/:id | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùå |
| PUT /live-assessments/:id | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùå |
| DELETE /live-assessments/:id | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå |
| GET /dashboard/assessments/* | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùå |

---

## üß™ Testes

**Arquivo:** `RF6_ASSESSMENTS_API_COLLECTION.http`

**Total:** 45+ requests cobrindo:
1. Autentica√ß√£o (1 request)
2. CRUD B√°sico (4 requests)
3. Listagem e Filtros (8 requests)
4. Detalhamento (1 request)
5. Update (4 requests)
6. Delete (2 requests)
7. M√©tricas (4 requests)
8. Valida√ß√µes e Seguran√ßa (4 requests)
9. Performance (4 requests)
10. Fluxo Completo E2E (5 requests)

---

## üìä M√©tricas e KPIs

### 1. Volume de Avalia√ß√µes
- Total de avalia√ß√µes criadas
- Avalia√ß√µes por per√≠odo (7/30 dias)
- Distribui√ß√£o por tipo (behavioral, technical, etc.)

### 2. Qualidade das Avalia√ß√µes
- Score m√©dio final
- Score m√©dio IA vs manual
- Distribui√ß√£o de scores (min/max/stddev)

### 3. Concord√¢ncia IA vs Humano
- Taxa de ajuste manual (%)
- Diferen√ßa m√©dia entre score_auto e score_manual
- Taxa de concord√¢ncia (diferen√ßa <= 1 ponto)
- Taxa de discord√¢ncia (diferen√ßa > 3 pontos)

### 4. Performance
- Tempo m√©dio de resposta dos candidatos
- Tempo de processamento da IA
- Avalia√ß√µes por entrevista

---

## üéØ Fluxo de Uso T√≠pico

1. **Durante a Entrevista:**
   - Candidato responde pergunta
   - Sistema registra resposta (`interview_answers`)
   - Sistema chama `POST /live-assessments` com `auto_evaluate: true`
   - IA avalia e retorna score + feedback
   - Recrutador v√™ avalia√ß√£o em tempo real

2. **Ap√≥s a Entrevista:**
   - Recrutador revisa avalia√ß√µes via `GET /live-assessments/interview/:id`
   - Ajusta scores/feedback via `PUT /live-assessments/:id`
   - Valida avalia√ß√µes finais (status ‚Üí `validated`)

3. **An√°lise de M√©tricas:**
   - Dashboard mostra concord√¢ncia IA vs humano
   - Identifica padr√µes de discord√¢ncia
   - Ajusta prompts da IA baseado em feedback

---

## ‚úÖ Status de Implementa√ß√£o

**Data:** 22/11/2025

**Migrations:**
- ‚úÖ 018_live_assessments.sql - Tabela (19 colunas, 8 √≠ndices, 1 trigger, 1 fun√ß√£o)
- ‚úÖ 019_assessment_metrics_views.sql - 5 views + fun√ß√£o get_assessment_metrics()

**API Endpoints:**
- ‚úÖ POST /api/live-assessments - Criar (autom√°tico via IA ou manual)
- ‚úÖ GET /api/live-assessments - Listar com 7 filtros
- ‚úÖ GET /api/live-assessments/:id - Detalhes
- ‚úÖ PUT /api/live-assessments/:id - Ajuste manual
- ‚úÖ DELETE /api/live-assessments/:id - Invalidar
- ‚úÖ GET /api/live-assessments/interview/:id - Avalia√ß√µes por entrevista
- ‚úÖ GET /api/dashboard/assessments/metrics - M√©tricas consolidadas
- ‚úÖ GET /api/dashboard/assessments/timeline - Timeline de avalia√ß√µes
- ‚úÖ GET /api/dashboard/assessments/by-interview - Estat√≠sticas por entrevista

**Integra√ß√£o IA:**
- ‚úÖ openRouterService.avaliarResposta() - Avalia√ß√£o autom√°tica via Grok

**Testes:**
- ‚úÖ RF6_ASSESSMENTS_API_COLLECTION.http - 45+ requests

**Documenta√ß√£o:**
- ‚úÖ RF6_DOCUMENTACAO.md (este arquivo)

**Pr√≥ximos Passos:**
- ‚è≥ Testes reais contra servidor
- ‚è≥ Seed data para demonstra√ß√£o
- ‚è≥ Frontend Flutter (telas de entrevista com avalia√ß√µes)

---

**Respons√°vel:** Time de Desenvolvimento TalentMatchIA
